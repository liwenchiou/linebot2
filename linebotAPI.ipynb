{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb1b886-bd73-42f2-a2eb-8a3f270ec59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\W20240908\\Lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec958510a2d413980c579a19a9bf904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add9f31b55804ba79654eb523abd2bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b41a7aa9464c4ba69f593c2f1018ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823d1d6597a44fd7b66b3a3913fe29a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce65ef493e314d86b05e796c2ad8ae51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/946M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4513a733c67a4755a42a02567e7a4e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.3.145:8080\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import subprocess\n",
    "import tempfile\n",
    "import whisper\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from flask import Flask, request, abort, jsonify, send_file\n",
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.exceptions import InvalidSignatureError\n",
    "from linebot.models import MessageEvent, AudioMessage, TextMessage, TextSendMessage, AudioSendMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import opencc\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# LINE bot 設置\n",
    "LINE_CHANNEL_ACCESS_TOKEN = 'gAdfjAoFL7SBmDXMjS1Zlglitvbg5h6jcC2o6O7Gzx8Zwu7a221OojUXsldgr71ZSiRjtLcblaIIwagGUduAzIwg/r2BniGjCnMyR/gUoiUrBOC9x3nsCdg5lUvpavu38eeCVBmdKI9HOiijKu2b1wdB04t89/1O/w1cDnyilFU='\n",
    "LINE_CHANNEL_SECRET = '36bce7862523d7bbdc296db4b0b1c82e'\n",
    "SERVER_URL = 'https://linebotapi-ejcw.onrender.com/webhook'\n",
    "STT_API_URL = 'http://180.218.16.187:30303/recognition_long_audio'\n",
    "TTS_API_URL = 'http://180.218.16.187:30303/getTTSfromText'\n",
    "LLM_API_URL = 'http://61.66.218.215:30315/llm_chat'\n",
    "SERVER_PORT = 8080\n",
    "line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)\n",
    "line_handler = WebhookHandler(LINE_CHANNEL_SECRET)\n",
    "# Whisper 和 LLM 模型設置\n",
    "stt_model = whisper.load_model(\"tiny\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\").to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "converter = opencc.OpenCC('s2t')\n",
    "# 模型功能\n",
    "def get_text_from_audio(audio_path):\n",
    "    with open(audio_path, 'rb') as f:\n",
    "        files = {'audio': (os.path.basename(audio_path), f, 'audio/mpeg')}\n",
    "        response = requests.post(STT_API_URL, files=files)\n",
    "        return response.json().get('result', '無法辨識音訊') if response.status_code == 200 else '錄音語音品質不佳，請再試試。'\n",
    "def get_response_from_llm(query):\n",
    "    payload = {'token': 'TEST', 'query': query, 'prompt_name': '艾妮機器人', 'max_tokens': '256'}\n",
    "    response = requests.post(LLM_API_URL, data=payload)\n",
    "    return response.json().get('result', '無法獲取回應')\n",
    "def get_audio_from_text(text):\n",
    "    payload = {'tone': '0', 'speed': '0', 'content': text, 'gender': '1'}\n",
    "    response = requests.post(TTS_API_URL, data=payload)\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return audio_path\n",
    "def run_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\", timeout=3600)\n",
    "        return result.returncode == 0, result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "# 路由和處理函數\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"Line Bot 已啟動並運作\"\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def callback():\n",
    "    signature = request.headers[\"X-Line-Signature\"]\n",
    "    body = request.get_data(as_text=True)\n",
    "    try:\n",
    "        line_handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "    return \"OK\"\n",
    "@app.route(\"/qa\", methods=[\"POST\"])\n",
    "def qa():\n",
    "    question = request.json.get('text')\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"未提供文本\"}), 400\n",
    "    answer = answer_question(question)\n",
    "    return jsonify({\"answer\": answer})\n",
    "@app.route(\"/transcribe\", methods=[\"POST\"])\n",
    "def transcribe():\n",
    "    audio_file = request.files.get('file')\n",
    "    if not audio_file:\n",
    "        return jsonify({\"error\": \"未上傳音訊檔案\"}), 400\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_audio_file:\n",
    "        audio_file.save(temp_audio_file.name)\n",
    "        audio = whisper.load_audio(temp_audio_file.name)\n",
    "        result = stt_model.transcribe(audio, language='zh')\n",
    "    os.remove(temp_audio_file.name)\n",
    "    return jsonify({\"transcription\": result['text']})\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "def synthesize():\n",
    "    content = request.form.get('content', '上傳資料內容有誤')\n",
    "    gender = request.form.get('gender', '1')\n",
    "    tone = request.form.get('tone', '0')\n",
    "    speed = request.form.get('speed', '0')\n",
    "    voices = {'1': \"zh-TW-YunJheNeural\", '0': \"zh-TW-HsiaoYuNeural\"}\n",
    "    voice = voices.get(gender, \"zh-TW-HsiaoChenNeural\")\n",
    "    pitch = f\"{tone}Hz\"\n",
    "    rate = f\"{speed}%\"\n",
    "    \n",
    "    output_path = f\"static/{int(time.time() * 1000)}.mp3\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    command = f'edge-tts --text \"{content}\" --write-media \"{output_path}\" --voice \"{voice}\" --pitch=\"{pitch}\" --rate=\"{rate}\"'\n",
    "    success, message = run_command(command)\n",
    "    if success:\n",
    "        return send_file(output_path, mimetype='audio/mpeg')\n",
    "    return jsonify({\"error\": message}), 500\n",
    "# 問答功能\n",
    "def answer_question(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True).to(llm_model.device)\n",
    "    outputs = llm_model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return converter.convert(answer)\n",
    "# Line handlers\n",
    "@line_handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_audio_message(event):\n",
    "    audio_path = f'static/{int(time.time())}.mp3'\n",
    "    with open(audio_path, 'wb') as fd:\n",
    "        for chunk in line_bot_api.get_message_content(event.message.id).iter_content():\n",
    "            fd.write(chunk)\n",
    "    text = get_text_from_audio(audio_path)\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "@line_handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_text_message(event):\n",
    "    text = event.message.text\n",
    "    llm_response = get_response_from_llm(text)\n",
    "    reply_audio_path = get_audio_from_text(llm_response)\n",
    "    if os.path.exists(reply_audio_path):\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            [\n",
    "                TextSendMessage(text=llm_response),\n",
    "                AudioSendMessage(original_content_url=f'{SERVER_URL}/{reply_audio_path}', duration=330)\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=\"合成語音時錯誤，請檢查 TTS Server\"))\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=SERVER_PORT, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7b62d-8e5d-411d-a6c7-2f86e2554ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
